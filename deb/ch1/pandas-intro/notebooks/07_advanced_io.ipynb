{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Read/Write IO\n",
    "\n",
    "Pandas provides built-in methods to read/write to almost every prominent Big Data file and storage type; making pandas one of the standard tools for converting data formats and loading data.\n",
    "\n",
    "<br/>\n",
    "\n",
    "### Writing to Cloud BigQuery\n",
    "\n",
    "One of the key applications of pandas is to transform data files and load into Big Data / Cloud tools for analytics. Pandas provides a built-in method called `.to_gbq()` to load Dataframes into BigQuery. \n",
    "\n",
    "The example below shows how you can use the `.to_gbq()` method to load data into BigQuery.\n",
    "\n",
    ":::tip .to_gbq() Performance\n",
    "\n",
    "Use `.to_gbq()` on smaller data loads (typically less than 1GB). The underlying method used by this method is not meant for large data loads. We recommend using this method for data loads in MBs range. Other techniques like writing directly to GCS and using BigQuery external tables is preferred method for large data loads in GB range.\n",
    "\n",
    ":::\n",
    "\n",
    "<br/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from google.oauth2 import service_account\n",
    "import os\n",
    "\n",
    "# read data fom csv\n",
    "flights = pd.read_csv('../data/flights.csv', header=0)\n",
    "\n",
    "# check if GCP ceredentials file is set\n",
    "if os.getenv('GOOGLE_APPLICATION_CREDENTIALS', default=None) is None:\n",
    "    raise RuntimeError(\"You forgot to set GOOGLE_APPLICATION_CREDENTIALS environment variable!\")\n",
    "\n",
    "# you can expplicitly load google credentials from a serivce account json file\n",
    "# this is OPTIONAL if GOOGLE_APPLICATION_CREDENTIALS environment variable is set\n",
    "credentials = service_account.Credentials.from_service_account_file(\n",
    "                    os.getenv('GOOGLE_APPLICATION_CREDENTIALS'))\n",
    "\n",
    "# schema is used to map dataframe fields to BigQuery data types\n",
    "# field data types should be defined as: https://cloud.google.com/bigquery/docs/schemasqbg_df\n",
    "schema = [\n",
    "    {'name': 'airline', 'type': 'STRING'},\n",
    "    {'name': 'src', 'type': 'STRING'},\n",
    "    {'name': 'dest', 'type': 'STRING'},\n",
    "    {'name': 'flight_number', 'type': 'STRING'},\n",
    "    {'name': 'departure_time', 'type': 'STRING'},\n",
    "    {'name': 'arrival_time', 'type': 'STRING'},\n",
    "]\n",
    "# gcp project name, bigquery dataset and tables names\n",
    "# EDIT values below based on your GCP environment\n",
    "project = 'deb-airliner'\n",
    "dataset = 'airline_data'\n",
    "table = 'pandas_flights'\n",
    "# filter output dataframe\n",
    "gbq_df = flights[['airline', 'src', 'dest', \n",
    "                  'flight_number', 'departure_time', 'arrival_time']]\n",
    "# write to bigquery using .to_gbq()\n",
    "gbq_df.to_gbq(\n",
    "    destination_table=f\"{dataset}.{table}\",\n",
    "    project_id=project,\n",
    "    chunksize= 2000,\n",
    "    if_exists='replace',\n",
    "    table_schema=schema,\n",
    "    progress_bar=False,\n",
    "    credentials=credentials,\n",
    ")\n",
    "print('done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}